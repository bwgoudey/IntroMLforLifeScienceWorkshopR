---
title: "Intro to Machine Learning For LIfe Sciences"
author: "Benjamin Goudey"
date: "2024-04-16"
output: html_document
---

```{r setup, include=FALSE}
# Load packages
#
library(rpart.plot)
library(tidyverse)
library(MASS)  # for mvnorm (multivariate normal data generation)
library(scales)  # for rescaling data'
library(remotes)
library(tidymodels)
library(DataExplorer)
library(pROC)

## Read in a set of helper functions
# Normally you'd just hve these locally but because we are using Google Colab, I found it
# easier to read these in directly from github.
source('helpers.R')
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
# Reand the dataset and make sure it's similar to sklearn's format
#source('./helpers.R')
devtools::source_url('https://raw.githubusercontent.com/bwgoudey/IntroMLforLifeScienceWorkshopR/main/helpers.R')
```

## Including Plots

You can also embed plots, for example:
### Load data
```{r pressure, echo=FALSE}
diabetes_df_raw <- read.csv("./RC_health_data_n3266.csv") %>% filter(!is.na(id))

diabetes_data <- load_diabetes_data(diabetes_df_raw, nsamples=2000, add_n_features=100) 

diabetes_study1_df <- diabetes_data[['study1']]%>% 
  mutate(map_mm_hg=dbp_mm_hg + (1/3)*(sbp_mm_hg-dbp_mm_hg)) %>% 
  dplyr::select(-sbp_mm_hg, -dbp_mm_hg, -alt_u_l, -bun_mmol_l, -ccr_umol_l, -year_of_followup, -height_cm, -weight_kg) %>% 
  relocate(map_mm_hg, .before = diabetes) %>% 
  as.data.frame()
diabetes_study2_df <- diabetes_data[['study2']]

diabetes_study3_df <- mplot::diabetes %>% 
  mutate(cholesterol_mmol_l=tc/38.67, fpg_mmol_l=glu/18, hdl_c_mmol_l=hdl/38.67, ldl_mmol_l=ldl/38.67, triglyceride_mmol_l=exp(ltg)/38.67) %>% 
  rename(age_y=age, gender_1_male_2_female=sex,bmi_kg_m2=bmi, map_mm_hg=map, diabetes=y) %>% 
  dplyr::select(-tch,-ltg, -tc, -glu, -hdl, -ldl) %>% 
  mutate(diabetes=factor(diabetes>120))
```
### Explored data
```{r report}
DataExplorer::plot_histogram()
```

```{r}

plot_roc_auc <- function(yp_train_df, yp_test_df) {
  rf_preds =rbind(yp_train_df, yp_test_df) %>% mutate(subset=factor(subset, c("train", "test")))

  auc_df = rf_preds %>% group_by(subset) %>% yardstick::roc_auc(truth = diabetes, .pred_0)  %>% rename(auc=.estimate)
  roc_curve_df<-rf_preds %>% group_by(subset) %>% yardstick::roc_curve(truth = diabetes, .pred_0)
  metrics_df = roc_curve_df %>% left_join(auc_df, by='subset')  
  
  # Plot training and external validation ROC curves
  metrics_df %>% 
    ggplot(aes(x=1-specificity, y=sensitivity, color=subset)) + 
    geom_point(size=0.5) + 
    theme_light(base_size = 16) + 
    geom_text(
      aes(x = 0.6, y = 0.3, label = paste("AUC =", round(auc,3))),
      size = 5,  inherit.aes = FALSE
  ) +  facet_wrap(~subset, nrow=1) + theme(legend.position = 'none')
}
```
## Ex 1
### Fitting a model
```{r}
# Setting up the model specification
logit_spec <- logistic_reg(mode = "classification", penalty = 0, engine = "glm")

# Setting up the workflow
workflow <- workflow() %>%
  add_model(logit_spec) %>%
  add_formula(diabetes ~ .) # Any variable on the left-hand side of the tilde (~) is considered the model outcome (here, arr_delay). On the right-hand side of the tilde are the predictors. Variables may be listed by name, or you can use the dot (.) to indicate all other variables as predictors.

# Fitting the model
fit <- workflow %>%
  fit(data = diabetes_data[['study1']]) 

# Make predictions
rf_training_pred <- 
  predict(fit, diabetes_data[['study1']], type = "prob") %>% 
  bind_cols(diabetes_data[['study1']] %>% dplyr::select(diabetes)) %>% 
  mutate(subset="train")

rf_testing_pred <- 
  predict(fit, diabetes_data[['study2']], type = "prob") %>% 
  bind_cols(diabetes_data[['study2']] %>% dplyr::select(diabetes)) %>% 
  mutate(subset="test")

plot_roc_auc(rf_training_pred, rf_testing_pred)

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
## Ex 2
### Compare different models
```{r}

# Define the models
models=list()
models[['log_reg']]=logistic_reg(mode = "classification", penalty = 0) %>% set_engine("glm")
models[['lasso']]=logistic_reg(penalty = 0.1, mixture = 1) %>% set_engine("glmnet")
models[['rf']]=rand_forest(mtry = 2, trees = 500, min_n = 3) %>% set_engine("randomForest")
models[['decision_tree']]=decision_tree(tree_depth = 5) %>% set_engine("rpart")

models = sapply(models, \(m) m %>% set_mode("classification"), simplify = F, USE.NAMES = T)

# Fit the model of interest
#Change this model 
current_model=models[["log_reg"]] %>% set_mode("classification")

model_fit <- current_model %>% 
  fit(diabetes ~ ., data = diabetes_data[['study1']])

# Get predicted labels from the model
yp_training <- predict(model_fit, diabetes_data[['study1']], type = "prob")$.pred_1
yp_testing <- predict(model_fit, diabetes_data[['study2']], type = "prob")$.pred_1

p1 <- plot_roc(y = as.numeric(diabetes_data[['study1']]$diabetes)-1, yp=yp_training, "Training")
p2 <- plot_roc(y = as.numeric(diabetes_data[['study2']]$diabetes)-1, yp=yp_testing, "Testing")

# Combine plots
p1 + p2

```

### Specific model output
```{r}
library(rpart.plot)

# Define the model
dt_model <- models[['decision_tree']] 

# Fit the model
dt_fit <- dt_model %>%
  fit(diabetes ~ ., data = diabetes_data[['study1']], model=T)

# Plot the decision tree
rpart.plot(dt_fit$fit, type = 3, extra = 104, cex = 0.8, fallen.leaves = TRUE, tweak = 1.2, 
           box.palette = "RdYlGn", shadow.col = "gray", nn = TRUE)
```
### Test multiple metrics
```{r}
train_test_split_rset <- df_to_rset(diabetes_df[['study1']], diabetes_df[['study2']], all=F)


train_test_split_rset <- initial_split_to_rset(train_test_split, diabetes_data[['study1']])
metrics_dict <- metric_set(accuracy, bal_accuracy, roc_auc, mn_log_loss)

multi_model_workflow <-  workflow_set(
    preproc = list("formula" = diabetes ~ .),
    models = models
  )

# Fit models with resampling and pass options
results <- multi_model_workflow %>%
  workflow_map(
    "fit_resamples",
    resamples = train_test_split_rset,
    metrics = metrics_dict,
    control = control_resamples(save_pred = TRUE)
  )

# Collect the metrics
metrics <- results %>%
  tune::collect_metrics(summarize=FALSE)

# Print the performance table
metrics %>% 
  pivot_wider(id_cols=c(wflow_id,id), names_from = `.metric`, values_from = `.estimate` ) %>% filter(id=='Training')%>% knitr::kable(digits=3, format='html')

metrics %>% 
  pivot_wider(id_cols=c(wflow_id,id), names_from = `.metric`, values_from = `.estimate` ) %>% filter(id=='Testing') %>% knitr::kable(digits=3, format='html')


```



# external eval
```{r}
# Setup three types of splits
# 1 Where we train on everything
# 2 Where we train on the trianing data and test on the training data
# 3 Where we train on the training data and test on the test data
train_test_split_rset <- initial_split_to_rset(train_test_split, diabetes_df, all=T, df2=diabetes_study2_df)

metrics_dict <- metric_set(roc_auc)

multi_model_workflow <-  workflow_set(
    preproc = list("formula" = diabetes ~ .),
    models = models
  )

# Fit models with resampling and pass options
results <- multi_model_workflow %>%
  workflow_map(
    "fit_resamples",
    resamples = train_test_split_rset,
    metrics = metrics_dict,
    control = control_resamples(save_pred = TRUE)
  )

# Collect the metrics
metrics <- results %>%
  tune::collect_metrics(summarize=FALSE, type = "wide")

metrics %>% 
  ggplot(aes(x=id, y=.estimate, fill=model)) + 
  geom_col(position='dodge') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) + 
  ylab("AUC") + theme_light(base_size=18)



```

```{r}
metrics_dict <- metric_set(roc_auc)

multi_model_workflow <-  workflow_set(
    preproc = list("formula" = diabetes ~ .),
    models = models
  )

# K-fold cross-validation
kfold=vfold_cv(diabetes_df, v = 3, repeats = 2)

# Fit models with resampling and pass options
results <- multi_model_workflow %>%
  workflow_map(
    "fit_resamples",
    resamples = kfold,
    metrics = metrics_dict,
    control = control_resamples(save_pred = TRUE)
  )

# Collect the metrics
metrics <- results %>%
  tune::collect_metrics(summarize=FALSE, type = "wide")

metrics %>% 
  ggplot(aes(x=model, y=.estimate, fill=model)) + 
  geom_boxplot(position='dodge') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) + 
  ylab("AUC") + theme_light(base_size=18)
```



